{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c044b2d-2812-48fb-ab04-f1e47c8193f8",
   "metadata": {},
   "source": [
    "# LLMs\n",
    "* Large Language Models (LLMs) are the core intelligence behind CrewAI agents.\n",
    "* CrewAI integrates with multiple LLM providers, giving you the flexibility to choose the right model for your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408d1f8-e862-4a04-8978-b6426f5d6c13",
   "metadata": {},
   "source": [
    "## Setting up the LLM\n",
    "There are three ways to configure LLMs in CrewAI:\n",
    "* .env file.\n",
    "* YAML configuration.\n",
    "* Direct code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfa559-a023-49a3-9335-b967acf5d9fe",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "When streaming is enabled, responses are delivered in chunks as theyâ€™re generated, creating a more responsive user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc98020-a149-4120-b5a2-6d3bda0fad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# Create an LLM with streaming enabled\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    stream=True  # Enable streaming\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cc4b3-7675-4b7a-98a3-33c2b2c18728",
   "metadata": {},
   "source": [
    "## Structured LLM Calls\n",
    "CrewAI supports structured responses from LLM calls by allowing you to define a response_format using a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836ba16-af5e-4d33-81cc-0ed178c43572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "class Dog(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    breed: str\n",
    "\n",
    "\n",
    "llm = LLM(model=\"gpt-4o\", response_format=Dog)\n",
    "\n",
    "response = llm.call(\n",
    "    \"Analyze the following messages and return the name, age, and breed. \"\n",
    "    \"Meet Kona! She is 3 years old and is a black german shepherd.\"\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Output:\n",
    "# Dog(name='Kona', age=3, breed='black german shepherd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d19a7-1eab-4fe0-ae1c-225b6f846d9a",
   "metadata": {},
   "source": [
    "## Ability to limit tokens used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9c2c0-f895-4448-b0e8-7e9fc9c60516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# CrewAI automatically handles:\n",
    "# 1. Token counting and tracking\n",
    "# 2. Content summarization when needed\n",
    "# 3. Task splitting for large contexts\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"openai/gpt-4\",\n",
    "    max_tokens=4000,  # Limit response length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a13fb-e766-4732-9cdc-fcfa2306c286",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "#### Use LLMs with larger context windows for extensive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe16080-79d1-4601-9c8e-79bdbc8d556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large context model\n",
    "llm = LLM(model=\"openai/gpt-4o\")  # 128K tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c74a1-a754-4615-b876-df9d98b684b1",
   "metadata": {},
   "source": [
    "#### Always include the provider prefix in model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fa7ea-1bb5-4046-9a9f-19c7defc6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct\n",
    "llm = LLM(model=\"openai/gpt-4\")\n",
    "\n",
    "# Incorrect\n",
    "llm = LLM(model=\"gpt-4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
