{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3f1244-30fd-4344-a0d8-b5c897137252",
   "metadata": {},
   "source": [
    "# Memory in CrewAI\n",
    "\n",
    "#### Benefits of using Memory\n",
    "* Adaptive Learning: Crews become more efficient over time, adapting to new information and refining their approach to tasks.\n",
    "* Enhanced Personalization: Memory enables agents to remember user preferences and historical interactions, leading to personalized experiences.\n",
    "* Improved Problem Solving: Access to a rich memory store aids agents in making more informed decisions, drawing on past learnings and contextual insights.\n",
    "\n",
    "#### Short-Term Memory\n",
    "Temporarily stores recent interactions and outcomes using RAG, enabling agents to recall and utilize information relevant to their current context during the current executions.\n",
    "* Contextual Awareness: With short-term and contextual memory, agents gain the ability to maintain context over a conversation or task sequence, leading to more coherent and relevant responses.\n",
    "\n",
    "#### Long-Term Memory\t\n",
    "Preserves valuable insights and learnings from past executions, allowing agents to build and refine their knowledge over time.\n",
    "* Experience Accumulation: Long-term memory allows agents to accumulate experiences, learning from past actions to improve future decision-making and problem-solving.\n",
    "\n",
    "#### Entity Memory\t\n",
    "Captures and organizes information about entities (people, places, concepts) encountered during tasks, facilitating deeper understanding and relationship mapping. Uses RAG for storing entity information.\n",
    "* Entity Understanding: By maintaining entity memory, agents can recognize and remember key entities, enhancing their ability to process and interact with complex information.\n",
    "\n",
    "#### Contextual Memory\t\n",
    "Maintains the context of interactions by combining ShortTermMemory, LongTermMemory, and EntityMemory, aiding in the coherence and relevance of agent responses over a sequence of tasks or a conversation.\n",
    "\n",
    "#### External Memory\t\n",
    "Enables integration with external memory systems and providers (like Mem0), allowing for specialized memory storage and retrieval across different applications. Supports custom storage implementations for flexible memory management.\n",
    "\n",
    "#### User Memory\t\n",
    "⚠️ DEPRECATED: This component is deprecated and will be removed in a future version. Please use External Memory instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a51a8a-567b-4ffa-9f10-9bc2bf2acb08",
   "metadata": {},
   "source": [
    "## Implementing Memory in a Crew\n",
    "\n",
    "#### By default, the memory system is disabled\n",
    "By default, the memory system is disabled, and you can ensure it is active by setting `memory=True` in the crew configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152a482-d8ac-410e-8b21-17994c4897de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Agent, Task, Process\n",
    "\n",
    "# Assemble your crew with memory capabilities\n",
    "my_crew = Crew(\n",
    "    agents=[...],\n",
    "    tasks=[...],\n",
    "    process=Process.sequential,\n",
    "    memory=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265975b7-cee6-471d-91c6-ca6095fcbd1d",
   "metadata": {},
   "source": [
    "#### The memory will use OpenAI embeddings by default\n",
    "The memory will use OpenAI embeddings by default, but you can change it by setting `embedder` to a different model.\n",
    "\n",
    "#### Where are short-term and long-term memories stored?\n",
    "* The ‘embedder’ only applies to Short-Term Memory which uses Chroma for RAG.\n",
    "* The Long-Term Memory uses SQLite3 to store task results.\n",
    "* **Currently, there is no way to override these storage implementations**.\n",
    "\n",
    "#### Where in your computer are saved this memory files?\n",
    "The data storage files are saved into a platform-specific location found using the `appdirs` package, and the name of the project can be overridden using the CREWAI_STORAGE_DIR environment variable. This means:\n",
    "\n",
    "1. **Platform-specific location using `appdirs`**:\n",
    "   - CrewAI saves its data (e.g., config files, cache, etc.) in a standard directory that depends on your operating system (Windows, macOS, Linux).\n",
    "   - This directory is determined using the [`appdirs`](https://pypi.org/project/appdirs/) Python package, which helps applications find appropriate locations for storing data, like:\n",
    "     - macOS: `~/Library/Application Support/<AppName>`\n",
    "     - Linux: `~/.local/share/<AppName>`\n",
    "     - Windows: `C:\\Users\\<User>\\AppData\\Local\\<AppName>`\n",
    "\n",
    "2. **Override with `CREWAI_STORAGE_DIR`**:\n",
    "   - If you don’t want CrewAI to use the default directory chosen by `appdirs`, you can set the environment variable `CREWAI_STORAGE_DIR` to specify a custom folder path.\n",
    "   - This is useful if you want to control where CrewAI keeps its files — for example, to use a shared network drive, keep things isolated for testing, or maintain a clean directory structure.\n",
    "\n",
    "Here’s how you can set the `CREWAI_STORAGE_DIR` environment variable on different operating systems:\n",
    "\n",
    "**Windows (Command Prompt)**\n",
    "\n",
    "```cmd\n",
    "set CREWAI_STORAGE_DIR=C:\\path\\to\\your\\custom\\folder\n",
    "```\n",
    "\n",
    "> This only lasts for the session. To make it permanent, you can set it via:\n",
    "- **Control Panel > System > Advanced system settings > Environment Variables**\n",
    "- Under \"User variables\", click **New**:\n",
    "  - Name: `CREWAI_STORAGE_DIR`\n",
    "  - Value: `C:\\path\\to\\your\\custom\\folder`\n",
    "\n",
    "**macOS or Linux (bash/zsh shell)**\n",
    "\n",
    "To set it for the current session:\n",
    "```bash\n",
    "export CREWAI_STORAGE_DIR=/path/to/your/custom/folder\n",
    "```\n",
    "\n",
    "To make it permanent, add the line above to your shell config file:\n",
    "- `~/.bashrc` or `~/.bash_profile` for **bash**\n",
    "- `~/.zshrc` for **zsh**\n",
    "\n",
    "Then run:\n",
    "```bash\n",
    "source ~/.bashrc   # or ~/.zshrc\n",
    "```\n",
    "\n",
    "Once this variable is set, CrewAI will store its data in the directory you specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a788ce-084b-47d5-bc22-da6b377ee2b9",
   "metadata": {},
   "source": [
    "## How to use custom Memory Instances like FAISS as the vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb31f7-cc94-4de2-b3c4-8eac0d36ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
    "from crewai.memory.storage.rag_storage import RAGStorage\n",
    "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
    "from typing import List, Optional\n",
    "\n",
    "# Assemble your crew with memory capabilities\n",
    "my_crew: Crew = Crew(\n",
    "    agents = [...],\n",
    "    tasks = [...],\n",
    "    process = Process.sequential,\n",
    "    memory = True,\n",
    "    # Long-term memory for persistent storage across sessions\n",
    "    long_term_memory = LongTermMemory(\n",
    "        storage=LTMSQLiteStorage(\n",
    "            db_path=\"/my_crew1/long_term_memory_storage.db\"\n",
    "        )\n",
    "    ),\n",
    "    # Short-term memory for current context using RAG\n",
    "    short_term_memory = ShortTermMemory(\n",
    "        storage = RAGStorage(\n",
    "                embedder_config={\n",
    "                    \"provider\": \"openai\",\n",
    "                    \"config\": {\n",
    "                        \"model\": 'text-embedding-3-small'\n",
    "                    }\n",
    "                },\n",
    "                type=\"short_term\",\n",
    "                path=\"/my_crew1/\"\n",
    "            )\n",
    "        ),\n",
    "    ),\n",
    "    # Entity memory for tracking key information about entities\n",
    "    entity_memory = EntityMemory(\n",
    "        storage=RAGStorage(\n",
    "            embedder_config={\n",
    "                \"provider\": \"openai\",\n",
    "                \"config\": {\n",
    "                    \"model\": 'text-embedding-3-small'\n",
    "                }\n",
    "            },\n",
    "            type=\"short_term\",\n",
    "            path=\"/my_crew1/\"\n",
    "        )\n",
    "    ),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c78ad1-4c2b-4b7a-8dd8-f200a9b050a8",
   "metadata": {},
   "source": [
    "## Let's explain the previous code\n",
    "The previous code sets up a `Crew` with multiple types of memory: **long-term**, **short-term**, and **entity memory**, each configured with a custom storage backend. Let’s break it down line-by-line and clarify how **FAISS** or **alternatives** come into play.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "1. **Memory Types Used**\n",
    "CrewAI supports memory for agents:\n",
    "- `LongTermMemory`: For persistent memory across sessions.\n",
    "- `ShortTermMemory`: For handling current context during interactions (like working memory).\n",
    "- `EntityMemory`: For remembering facts about specific entities (e.g., a person or company).\n",
    "\n",
    "2. **Storage Backends**\n",
    "Each memory type can plug into a **storage engine**. These engines determine where and how embeddings and knowledge are stored and queried.\n",
    "\n",
    "The two shown here are:\n",
    "- `LTMSQLiteStorage`: SQLite-based storage for **long-term memory**.\n",
    "- `RAGStorage`: RAG = Retrieval-Augmented Generation. This is often where **FAISS** or vector DBs come in.\n",
    "\n",
    "#### Imports\n",
    "\n",
    "```python\n",
    "from crewai import Crew, Process\n",
    "from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory\n",
    "from crewai.memory.storage.rag_storage import RAGStorage\n",
    "from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage\n",
    "```\n",
    "This imports the memory-related components and two storage backends: one for long-term (SQLite) and one for short-term/entity (RAG).\n",
    "\n",
    "#### Setting up the Crew\n",
    "```python\n",
    "my_crew: Crew = Crew(\n",
    "    agents = [...],\n",
    "    tasks = [...],\n",
    "    process = Process.sequential,\n",
    "    memory = True,\n",
    "```\n",
    "This initializes a `Crew` object, enables memory, and sets it to work sequentially through tasks.\n",
    "\n",
    "#### Long-Term Memory\n",
    "```python\n",
    "long_term_memory = LongTermMemory(\n",
    "    storage=LTMSQLiteStorage(\n",
    "        db_path=\"/my_crew1/long_term_memory_storage.db\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "- Uses `LTMSQLiteStorage` to persist data.\n",
    "- **No FAISS here**—just plain SQLite.\n",
    "\n",
    "#### Short-Term and Entity Memory\n",
    "```python\n",
    "short_term_memory = ShortTermMemory(\n",
    "    storage = RAGStorage(\n",
    "        embedder_config={\n",
    "            \"provider\": \"openai\",\n",
    "            \"config\": {\n",
    "                \"model\": 'text-embedding-3-small'\n",
    "            }\n",
    "        },\n",
    "        type=\"short_term\",\n",
    "        path=\"/my_crew1/\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "- Uses `RAGStorage` for embedding-based retrieval.\n",
    "- The `embedder_config` defines how to convert text to vectors (OpenAI embeddings here).\n",
    "- **This is where FAISS is used internally**: `RAGStorage` stores and retrieves vectors, and it uses FAISS under the hood.\n",
    "\n",
    "Same logic applies to `EntityMemory`.\n",
    "\n",
    "#### Where Is FAISS Used?\n",
    "\n",
    "**FAISS is not explicitly imported or configured in this code.** However:\n",
    "- `RAGStorage`'s implementation uses FAISS as the vector store backend, then **FAISS is used internally**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9847a-ef83-4e7b-848e-03ba24eaae9e",
   "metadata": {},
   "source": [
    "## Security Considerations\n",
    "* Use environment variables for storage paths (e.g., CREWAI_STORAGE_DIR).\n",
    "* Never hardcode sensitive information like database credentials.\n",
    "* Consider access permissions for storage directories.\n",
    "* Use relative paths when possible to maintain portability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae38b4-0dcb-4ff7-8ba6-0647a3cd85e5",
   "metadata": {},
   "source": [
    "## CrewAI allows integrating Mem0 for Enhanced User Memory\n",
    "\n",
    "[Mem0](https://mem0.ai/) is an open-source, self-improving memory layer designed for Large Language Model (LLM) applications, aiming to enable personalized and context-aware AI experiences. It addresses the stateless nature of traditional LLMs by providing mechanisms to remember and learn from user interactions over time.\n",
    "\n",
    "#### What Is Mem0?\n",
    "\n",
    "Mem0 functions as an intelligent memory system for AI applications, allowing them to:\n",
    "\n",
    "- **Retain User Preferences**: Mem0 stores information about user interactions, enabling AI systems to recall past conversations and preferences.\n",
    "\n",
    "- **Adapt to Individual Needs**: By learning from ongoing interactions, Mem0 helps AI applications tailor responses to individual users. \n",
    "\n",
    "- **Continuously Improve**: The system evolves with each interaction, refining its understanding and enhancing the user experience over time.\n",
    "\n",
    "These capabilities are particularly beneficial for applications like customer support chatbots, personal AI assistants, and autonomous systems.\n",
    "\n",
    "#### How Mem0 Works\n",
    "\n",
    "Mem0 employs a hybrid datastore architecture that combines:\n",
    "\n",
    "- **Graph Stores**: To capture relationships between different pieces of information.\n",
    "\n",
    "- **Vector Stores**: For efficient similarity searches based on embeddings.\n",
    "\n",
    "- **Key-Value Stores**: To quickly retrieve specific data points. \n",
    "\n",
    "This architecture allows Mem0 to manage various types of memory, including:\n",
    "\n",
    "- **Long-Term Memory**: Persistent information retained across sessions.\n",
    "\n",
    "- **Short-Term Memory**: Contextual information relevant to the current session.\n",
    "\n",
    "- **Semantic Memory**: Understanding of concepts and facts.\n",
    "\n",
    "- **Episodic Memory**: Recollection of specific events or interactions.\n",
    "\n",
    "The system is designed to be easily integrated into existing AI applications, with support for various platforms and frameworks .\n",
    "\n",
    "#### Performance Highlights\n",
    "\n",
    "According to recent research, Mem0 demonstrates significant improvements over traditional memory systems:\n",
    "\n",
    "- **Accuracy**: Achieves 26% higher accuracy compared to OpenAI's memory on the LOCOMO benchmark.\n",
    "\n",
    "- **Latency**: Delivers responses 91% faster than full-context approaches.\n",
    "\n",
    "- **Token Efficiency**: Reduces token usage by 90%, lowering operational costs.\n",
    "\n",
    "These enhancements make Mem0 a compelling choice for developers seeking to build more efficient and personalized AI applications .\n",
    "\n",
    "#### Integration and Use Cases\n",
    "\n",
    "Mem0 can be integrated into AI applications through its SDKs or APIs. Developers can choose between a hosted platform or a self-hosted open-source package. Use cases include:\n",
    "\n",
    "- **Customer Support**: Chatbots that remember past interactions to provide more accurate assistance.\n",
    "\n",
    "- **Personal AI Companions**: Assistants that adapt to user preferences over time.\n",
    "\n",
    "- **Healthcare Applications**: Systems that track patient history for personalized care.\n",
    "\n",
    "- **Productivity Tools**: Applications that learn from user behavior to optimize workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75168b-baac-4b77-bdba-06e426833b84",
   "metadata": {},
   "source": [
    "## Miscelanea: Using Mem0 in a Crew, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d755ea4-0de3-44cd-876b-ec57ec57c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Crew, Process\n",
    "from mem0 import MemoryClient\n",
    "\n",
    "# Set environment variables for Mem0\n",
    "os.environ[\"MEM0_API_KEY\"] = \"m0-xx\"\n",
    "\n",
    "# Step 1: Create a Crew with User Memory\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[...],\n",
    "    tasks=[...],\n",
    "    verbose=True,\n",
    "    process=Process.sequential,\n",
    "    memory=True,\n",
    "    memory_config={\n",
    "        \"provider\": \"mem0\",\n",
    "        \"config\": {\"user_id\": \"john\"},\n",
    "        \"user_memory\" : {} #Set user_memory explicitly to a dictionary, we are working on this issue.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cdc13a-4363-4507-b826-30662f208823",
   "metadata": {},
   "source": [
    "## Miscelanea: Mem0 possibilities, Embedder Options, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebab5f0-9299-4a64-a332-21da2899bc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
