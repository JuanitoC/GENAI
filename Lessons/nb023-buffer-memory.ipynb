{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Memory\n",
    "* Save your conversation with the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759d27a-94f3-4141-945d-065f2095bffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intro\n",
    "* Ability to store information about past interactions.\n",
    "* **Most of memory-related functionality in LangChain is marked as beta**. This is for two reasons:\n",
    "    1. Most functionality are not production ready.\n",
    "    2. Most functionality work with Legacy chains, not the newer LCEL syntax.\n",
    "* **The main exception to this is the ChatMessageHistory functionality**. This functionality is largely production ready and does integrate with LCEL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## LangChain documentation on Memory\n",
    "* See the LangChain documentation page on Memory [here](https://python.langchain.com/v0.1/docs/modules/memory/).\n",
    "* See the LangChain documentation page on how to use ChatMessageHistory with LCEL [here](https://python.langchain.com/v0.1/docs/expression_language/how_to/message_history/).\n",
    "* See the LangChain documentation page on the various ChatMessageHistory integrations [here](https://python.langchain.com/v0.1/docs/integrations/memory/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f9bf4-bcc6-4283-b894-0c4dd985f445",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0233ade-b3d9-4dd9-963c-ff8836f4fd5e",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 001-simple-chain.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1d742-ee3b-42e4-9db6-7c1c8d5b3923",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **001-conversation-buffer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46b134-c502-47f1-b67f-c5b03bff1d0a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fca939-bd83-4d5b-8e34-57cdbe855260",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead3bd7-e4af-45b5-a770-64742c3bca77",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7365e2af-d5f2-481e-9892-babd5f781ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c1af4-733f-4139-9eda-9a546614a3f5",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb4a8e-7d41-40f7-aae7-ca4cd3e4cf21",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e131c1-3458-4941-848b-a0c54cea0d1c",
   "metadata": {},
   "source": [
    "## Buffer Memory\n",
    "* ConversationBufferMemory keeps a list of chat messages in a buffer and passes those into the prompt template.\n",
    "* A buffer refers to a **temporary storage area in memory** used to hold data. Here, the buffer specifically holds chat messages before they are processed or used in some way, such as being passed into a prompt template.\n",
    "* In simple terms, a buffer is like a waiting room for data. It's a temporary holding spot where data can stay until it's ready to be used or processed. Imagine you're cooking and you chop up vegetables before you need to cook them. Instead of chopping each vegetable right before it goes in the pan, you chop them all at once and put them aside on a cutting board. That cutting board with the chopped vegetables is like a buffer â€” it holds everything ready for you until you're ready to use it. This way, when you need the vegetables, they are all prepared and ready to go, making the cooking process smoother and faster.\n",
    "* As you can see in the following example, ConversationBufferMemory was used mostly in the initial versions of LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9422509-359b-49a4-ad33-404244c91645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\131978567.py:23: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\131978567.py:25: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c4c85a-ad84-4aa2-98b8-24ce8428a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Julio and I have moved 33 times.\n",
      "AI: Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\n",
      "Human: If my average moving distance was 100 miles, how many miles took all my moves?\n",
      "AI: To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\n",
      "\n",
      "Total distance = Number of moves x Average distance per move\n",
      "\n",
      "Total distance = 33 moves x 100 miles = 3300 miles\n",
      "\n",
      "So, all your moves totaled 3300 miles. That's quite a journey!\n",
      "Human: Do you remember my name?\n",
      "AI: Yes, Julio!\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, Julio!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello again, Julio! How can I help you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Hello again, Julio! How can I help you today?'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation.invoke({\"question\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22e732b-f3e5-42e2-a30e-43cf544fd84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Julio and I have moved 33 times.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Julio and I have moved 33 times.',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"My name is Julio and I have moved 33 times.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9320c2ec-7e35-46a5-8a19-eb1c85144c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Julio and I have moved 33 times.\n",
      "AI: Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\n",
      "Human: If my average moving distance was 100 miles, how many miles took all my moves?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'If my average moving distance was 100 miles, how many miles took all my moves?',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={})],\n",
       " 'text': \"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"If my average moving distance was 100 miles, how many miles took all my moves?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50060c5-aa4a-44da-92c5-355fe8a28ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How are you today?\n",
      "Human: My name is Julio and I have moved 33 times.\n",
      "AI: Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\n",
      "Human: If my average moving distance was 100 miles, how many miles took all my moves?\n",
      "AI: To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\n",
      "\n",
      "Total distance = Number of moves x Average distance per move\n",
      "\n",
      "Total distance = 33 moves x 100 miles = 3300 miles\n",
      "\n",
      "So, all your moves totaled 3300 miles. That's quite a journey!\n",
      "Human: Do you remember my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Do you remember my name?',\n",
       " 'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, Julio!', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'Yes, Julio!'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Do you remember my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1ad132-fd8b-4355-bab0-ef8605d3650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, Julio!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e4331e-8e2e-4502-8de4-fda0da8aff8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hello! How are you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Julio and I have moved 33 times.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Nice to meet you, Julio! That's quite a lot of moves. What made you move so many times?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='If my average moving distance was 100 miles, how many miles took all my moves?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"To calculate the total distance of all your moves, we can multiply the number of moves by the average distance per move.\\n\\nTotal distance = Number of moves x Average distance per move\\n\\nTotal distance = 33 moves x 100 miles = 3300 miles\\n\\nSo, all your moves totaled 3300 miles. That's quite a journey!\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Do you remember my name?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Yes, Julio!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440a384-8c9f-4802-8fa9-9a042d200ced",
   "metadata": {},
   "source": [
    "## Conversation Buffer Window Memory\n",
    "Similar to the previous one, but **you can limit the number of conversational exchanges stored in memory**. For example, you can set it so it only remembers the last 3 questions and answers of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224f6a07-66a5-4302-adcb-08a1544ae288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615a06d0-092f-4cb7-857c-6750c4643c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\3645135692.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k=3)\n"
     ]
    }
   ],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3567844-9ca9-4454-a973-c03de283bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\2450156885.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation_window = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "conversation_window = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = window_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58ef7681-d99a-484f-bb64-08dbcb794654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Julio\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi, my name is Julio',\n",
       " 'history': '',\n",
       " 'response': \"Hello, Julio! It's nice to meet you. How can I assist you today?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"Hi, my name is Julio\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b3807d3-6ee3-49c4-9adb-59013f7e54d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Julio\n",
      "AI: Hello, Julio! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite color is blue',\n",
       " 'history': \"Human: Hi, my name is Julio\\nAI: Hello, Julio! It's nice to meet you. How can I assist you today?\",\n",
       " 'response': \"Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite color is blue\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6221d09e-5663-43cb-aaa5-e605bb0a2e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Julio\n",
      "AI: Hello, Julio! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\n",
      "Human: My favorite animals are dogs\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite animals are dogs',\n",
       " 'history': \"Human: Hi, my name is Julio\\nAI: Hello, Julio! It's nice to meet you. How can I assist you today?\\nHuman: My favorite color is blue\\nAI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\",\n",
       " 'response': 'Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite animals are dogs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2aa84d1-5d9d-4c1e-8d29-c806c69a2e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Julio\n",
      "AI: Hello, Julio! It's nice to meet you. How can I assist you today?\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I like to drive a vespa scooter in the city',\n",
       " 'history': \"Human: Hi, my name is Julio\\nAI: Hello, Julio! It's nice to meet you. How can I assist you today?\\nHuman: My favorite color is blue\\nAI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\\nHuman: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\",\n",
       " 'response': 'Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"I like to drive a vespa scooter in the city\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c60e52d9-907d-4c29-8720-97019af6b120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite color is blue\n",
      "AI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\n",
      "Human: My favorite city is San Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite city is San Francisco',\n",
       " 'history': \"Human: My favorite color is blue\\nAI: Blue is a great color! It's often associated with calmness, stability, and trustworthiness. Do you have a specific reason why blue is your favorite color?\\nHuman: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\\nHuman: I like to drive a vespa scooter in the city\\nAI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\",\n",
       " 'response': \"San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite city is San Francisco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c173dc8-3fe5-4913-942c-89f58c3a2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite animals are dogs\n",
      "AI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\n",
      "Human: My favorite city is San Francisco\n",
      "AI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\n",
      "Human: My favorite season is summer\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite season is summer',\n",
       " 'history': \"Human: My favorite animals are dogs\\nAI: Dogs are wonderful animals! They are known for their loyalty, companionship, and playfulness. There are so many different breeds with unique characteristics. Do you have a favorite breed of dog?\\nHuman: I like to drive a vespa scooter in the city\\nAI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\\nHuman: My favorite city is San Francisco\\nAI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\",\n",
       " 'response': \"Summer is a popular season for many people because of the warm weather, longer days, and opportunities for outdoor activities like swimming, barbecuing, and going to the beach. It's a great time for vacations and spending time with friends and family. Do you have any special summer traditions or activities that you enjoy?\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite season is summer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "239714b5-e8df-4085-b1df-4409388a8d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I like to drive a vespa scooter in the city\n",
      "AI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\n",
      "Human: My favorite city is San Francisco\n",
      "AI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\n",
      "Human: My favorite season is summer\n",
      "AI: Summer is a popular season for many people because of the warm weather, longer days, and opportunities for outdoor activities like swimming, barbecuing, and going to the beach. It's a great time for vacations and spending time with friends and family. Do you have any special summer traditions or activities that you enjoy?\n",
      "Human: What is my favorite color?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my favorite color?',\n",
       " 'history': \"Human: I like to drive a vespa scooter in the city\\nAI: Vespa scooters are a stylish and convenient way to navigate city streets! They have a classic design and are known for being fuel-efficient. Do you enjoy the feeling of riding a Vespa around the city?\\nHuman: My favorite city is San Francisco\\nAI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\\nHuman: My favorite season is summer\\nAI: Summer is a popular season for many people because of the warm weather, longer days, and opportunities for outdoor activities like swimming, barbecuing, and going to the beach. It's a great time for vacations and spending time with friends and family. Do you have any special summer traditions or activities that you enjoy?\",\n",
       " 'response': \"I'm sorry, I don't have access to that information. What is your favorite color?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"What is my favorite color?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56db514f-da49-4cea-a424-0977969d49c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: My favorite city is San Francisco\n",
      "AI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\n",
      "Human: My favorite season is summer\n",
      "AI: Summer is a popular season for many people because of the warm weather, longer days, and opportunities for outdoor activities like swimming, barbecuing, and going to the beach. It's a great time for vacations and spending time with friends and family. Do you have any special summer traditions or activities that you enjoy?\n",
      "Human: What is my favorite color?\n",
      "AI: I'm sorry, I don't have access to that information. What is your favorite color?\n",
      "Human: My favorite city is San Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My favorite city is San Francisco',\n",
       " 'history': \"Human: My favorite city is San Francisco\\nAI: San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\\nHuman: My favorite season is summer\\nAI: Summer is a popular season for many people because of the warm weather, longer days, and opportunities for outdoor activities like swimming, barbecuing, and going to the beach. It's a great time for vacations and spending time with friends and family. Do you have any special summer traditions or activities that you enjoy?\\nHuman: What is my favorite color?\\nAI: I'm sorry, I don't have access to that information. What is your favorite color?\",\n",
       " 'response': \"San Francisco is a vibrant city with a rich history and diverse culture! It's known for iconic landmarks like the Golden Gate Bridge, Alcatraz Island, and the historic cable cars. The city also has a reputation for its fantastic dining scene and beautiful views. What do you love most about San Francisco?\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window({\"input\": \"My favorite city is San Francisco\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e38dd80-2f5f-427f-81fd-d7894ce98e8b",
   "metadata": {},
   "source": [
    "## Conversation Token Buffer Memory\n",
    "Similar to the previous one, but this time **you can limit the number of tokens stored in memory**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf7137-b952-4874-ae92-a25d46d253d9",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d549bb9c-9c73-4739-b0dc-ac6bad69ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a086fa-235c-4179-9f76-30453b2457f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d203b6a0-4657-46ea-b8d1-6cce499d79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\130807733.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  token_memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "token_memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9163cbcd-3ea9-4c17-9ee4-3f469eb42b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_token = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = token_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e552b-f1b7-41f8-abbf-60e9caf6a8e5",
   "metadata": {},
   "source": [
    "## Conversation Summary Memory\n",
    "**Stores a summary** of the previous conversational exchanges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "470498d0-240c-4ed3-ad5c-7459f1ef1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30faeb8c-b267-44e6-b05d-012b357946c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_19212\\3597302779.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "summary_memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c77ec6c6-d1ea-4fca-ada4-288557995613",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = summary_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "848cbaa3-150f-4985-965b-9161aebc6b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Kurt Cobain dropped out of high school, \n",
      "then worked there as a janitor Even though he was by all accounts a slob, \n",
      "Kurt Cobain worked as a janitor at Weatherwax High School, not long after \n",
      "dropping out of that very school. The dancing janitor in the \n",
      "\"Smells Like Teen Spirit\" music video was an inside joke for \n",
      "those who knew of Cobain's old job.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Kurt Cobain dropped out of high school, \\nthen worked there as a janitor Even though he was by all accounts a slob, \\nKurt Cobain worked as a janitor at Weatherwax High School, not long after \\ndropping out of that very school. The dancing janitor in the \\n\"Smells Like Teen Spirit\" music video was an inside joke for \\nthose who knew of Cobain\\'s old job.\\n',\n",
       " 'history': '',\n",
       " 'response': 'Wow, that\\'s some interesting trivia about Kurt Cobain! It\\'s always fascinating to learn little details about famous people\\'s lives. Did you know that the janitor character in the \"Smells Like Teen Spirit\" music video was actually played by actor Tony De La Rosa, and not Kurt Cobain himself? It was definitely a clever nod to Cobain\\'s past as a janitor at Weatherwax High School. It\\'s amazing how these little connections can add so much depth to a music video. If you have any more questions or facts to share, feel free to let me know!'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_summary({\"input\": \"\"\"Kurt Cobain dropped out of high school, \n",
    "then worked there as a janitor Even though he was by all accounts a slob, \n",
    "Kurt Cobain worked as a janitor at Weatherwax High School, not long after \n",
    "dropping out of that very school. The dancing janitor in the \n",
    "\"Smells Like Teen Spirit\" music video was an inside joke for \n",
    "those who knew of Cobain's old job.\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26545b98-d290-48fe-b3e9-341ff195ccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared.\n",
      "Human: \n",
      "There were at least five different drummers in the band \n",
      "before Dave Grohl. Cobain and Novoselic were always members \n",
      "of Nirvanaâ€”formerly known as Skid Row, Pen Cap Chew, Bliss, \n",
      "and Ted Ed Fredâ€”but finding a permanent drummer proved to be \n",
      "even harder than coming up with a decent band name. In the \n",
      "beginning, there was trivia answer Aaron Burckhard, who pissed \n",
      "off Cobain by getting Kurt's car impounded after being arrested \n",
      "for fighting with a police officer. Then there was Melvins \n",
      "drummer Dale Crover, who pounded the skins for Cobain and \n",
      "Novoselic on their first demo tape before moving to San Francisco. \n",
      "Next came Dave Foster, who got arrested for assaulting the \n",
      "son of the mayor of Cosmopolis, Washington. Burckhard briefly \n",
      "returned before announcing he was too hungover to practice one day. \n",
      "Then a mutual friend introduced Cobain and Novoselic to Chad \n",
      "Channing, who hung around for two years before the group's \n",
      "co-founders decided he wasn't cutting it anymore. Mudhoney \n",
      "drummer Dan Peters played on the \"Sliver\" single.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\nThere were at least five different drummers in the band \\nbefore Dave Grohl. Cobain and Novoselic were always members \\nof Nirvanaâ€”formerly known as Skid Row, Pen Cap Chew, Bliss, \\nand Ted Ed Fredâ€”but finding a permanent drummer proved to be \\neven harder than coming up with a decent band name. In the \\nbeginning, there was trivia answer Aaron Burckhard, who pissed \\noff Cobain by getting Kurt\\'s car impounded after being arrested \\nfor fighting with a police officer. Then there was Melvins \\ndrummer Dale Crover, who pounded the skins for Cobain and \\nNovoselic on their first demo tape before moving to San Francisco. \\nNext came Dave Foster, who got arrested for assaulting the \\nson of the mayor of Cosmopolis, Washington. Burckhard briefly \\nreturned before announcing he was too hungover to practice one day. \\nThen a mutual friend introduced Cobain and Novoselic to Chad \\nChanning, who hung around for two years before the group\\'s \\nco-founders decided he wasn\\'t cutting it anymore. Mudhoney \\ndrummer Dan Peters played on the \"Sliver\" single.\\n',\n",
       " 'history': 'System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared.',\n",
       " 'response': \"Wow, that's quite a history of drummers for Nirvana before Dave Grohl! It's interesting to see how the lineup changes shaped the band's sound and direction. Each drummer probably brought something unique to the table during their time with the band. It must have been challenging for Cobain and Novoselic to find the right fit for their vision. Do you know any more trivia or facts about Nirvana's early days?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_summary({\"input\": \"\"\"\n",
    "There were at least five different drummers in the band \n",
    "before Dave Grohl. Cobain and Novoselic were always members \n",
    "of Nirvanaâ€”formerly known as Skid Row, Pen Cap Chew, Bliss, \n",
    "and Ted Ed Fredâ€”but finding a permanent drummer proved to be \n",
    "even harder than coming up with a decent band name. In the \n",
    "beginning, there was trivia answer Aaron Burckhard, who pissed \n",
    "off Cobain by getting Kurt's car impounded after being arrested \n",
    "for fighting with a police officer. Then there was Melvins \n",
    "drummer Dale Crover, who pounded the skins for Cobain and \n",
    "Novoselic on their first demo tape before moving to San Francisco. \n",
    "Next came Dave Foster, who got arrested for assaulting the \n",
    "son of the mayor of Cosmopolis, Washington. Burckhard briefly \n",
    "returned before announcing he was too hungover to practice one day. \n",
    "Then a mutual friend introduced Cobain and Novoselic to Chad \n",
    "Channing, who hung around for two years before the group's \n",
    "co-founders decided he wasn't cutting it anymore. Mudhoney \n",
    "drummer Dan Peters played on the \"Sliver\" single.\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f1ef76-31d3-4f81-9f16-21111c6b4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared, like the history of Nirvana's drummers before Dave Grohl.\n",
      "AI: Wow, that's quite a history of drummers for Nirvana before Dave Grohl! It's interesting to see how the lineup changes shaped the band's sound and direction. Each drummer probably brought something unique to the table during their time with the band. It must have been challenging for Cobain and Novoselic to find the right fit for their vision. Do you know any more trivia or facts about Nirvana's early days?\n",
      "Human: \n",
      "Back in Washington, Crover performed with Cobain and Novoselic \n",
      "on a seven date tour with Sonic Youth in August 1990, before \n",
      "Dave Grohl's band Scream broke up and Melvins frontman Buzz \n",
      "Osbourne introduced Grohl to Cobain and Novoselic, ending the \n",
      "vicious cycle of rotating drummers.\n",
      "\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"\\nBack in Washington, Crover performed with Cobain and Novoselic \\non a seven date tour with Sonic Youth in August 1990, before \\nDave Grohl's band Scream broke up and Melvins frontman Buzz \\nOsbourne introduced Grohl to Cobain and Novoselic, ending the \\nvicious cycle of rotating drummers.\\n\",\n",
       " 'history': 'System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared, like the history of Nirvana\\'s drummers before Dave Grohl.\\nAI: Wow, that\\'s quite a history of drummers for Nirvana before Dave Grohl! It\\'s interesting to see how the lineup changes shaped the band\\'s sound and direction. Each drummer probably brought something unique to the table during their time with the band. It must have been challenging for Cobain and Novoselic to find the right fit for their vision. Do you know any more trivia or facts about Nirvana\\'s early days?',\n",
       " 'response': \"That's an interesting piece of trivia! It's amazing how interconnected the music scene was back then, with all these bands collaborating and influencing each other. It seems like fate brought Dave Grohl to Nirvana at just the right time. It's fascinating to think about how different things might have been if he hadn't joined the band. Do you know any more details about how that introduction played out?\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_summary({\"input\": \"\"\"\n",
    "Back in Washington, Crover performed with Cobain and Novoselic \n",
    "on a seven date tour with Sonic Youth in August 1990, before \n",
    "Dave Grohl's band Scream broke up and Melvins frontman Buzz \n",
    "Osbourne introduced Grohl to Cobain and Novoselic, ending the \n",
    "vicious cycle of rotating drummers.\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba74e086-8885-49a5-b35c-264c0e0f22ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared, like the history of Nirvana's drummers before Dave Grohl, discussing how each drummer contributed uniquely to the band's sound. The human shares more trivia about Crover performing with Cobain and Novoselic before the introduction of Dave Grohl, highlighting the challenges in finding the right fit for Nirvana's lineup.\n",
      "AI: That's an interesting piece of trivia! It's amazing how interconnected the music scene was back then, with all these bands collaborating and influencing each other. It seems like fate brought Dave Grohl to Nirvana at just the right time. It's fascinating to think about how different things might have been if he hadn't joined the band. Do you know any more details about how that introduction played out?\n"
     ]
    }
   ],
   "source": [
    "print(summary_memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed27a282-9e83-47cc-bfb7-739baf36ce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human shares a piece of trivia about Kurt Cobain working as a janitor at Weatherwax High School after dropping out. The AI finds this interesting and expands on the fact by mentioning that the janitor character in the \"Smells Like Teen Spirit\" music video was played by actor Tony De La Rosa. The AI appreciates how these details add depth to the music video and invites more questions and facts to be shared, like the history of Nirvana\\'s drummers before Dave Grohl, discussing how each drummer contributed uniquely to the band\\'s sound. The human shares more trivia about Crover performing with Cobain and Novoselic before the introduction of Dave Grohl, highlighting the challenges in finding the right fit for Nirvana\\'s lineup.\\nAI: That\\'s an interesting piece of trivia! It\\'s amazing how interconnected the music scene was back then, with all these bands collaborating and influencing each other. It seems like fate brought Dave Grohl to Nirvana at just the right time. It\\'s fascinating to think about how different things might have been if he hadn\\'t joined the band. Do you know any more details about how that introduction played out?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
