{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea998dc2-12cc-42c6-9973-e9393022a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d530b7-4777-46bd-a3af-96acd82666c3",
   "metadata": {},
   "source": [
    "## LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2b3a3-ac1b-4da1-a5d3-6627d40ef87b",
   "metadata": {},
   "source": [
    "*Log In at https://smith.langchain.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd836d0-0454-48a3-8836-132df3d9e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGCHAIN_TRACING_V2=true\n",
    "# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "# LANGCHAIN_API_KEY=<your-api-key>\n",
    "# LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea19f948-566b-4677-9d04-034efa5c99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0face3-7eee-4b87-9381-c94f1ce984d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_7052\\3282332252.py:6: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(\"How many brothers had Napoleon Bonaparte?\", callbacks=[tracer])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Napoleon Bonaparte had three brothers: Joseph, Lucien, and Jerome.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "tracer = LangChainTracer(project_name=\"Napoleon v1\")\n",
    "llm.predict(\"How many brothers had Napoleon Bonaparte?\", callbacks=[tracer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153d81c1-d0ed-42a8-869a-7c7b55fca6fd",
   "metadata": {},
   "source": [
    "**See updates in the Projects Area in LangSmith**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36085d6-eceb-4dae-ac3a-5bd38acbc978",
   "metadata": {},
   "source": [
    "## Basic LangSmith Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572831d-e265-4e2a-aeed-c333825afbfa",
   "metadata": {},
   "source": [
    "**Create a new project with LangChainTracer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f8cafb-4f13-42e9-857a-ea0c8acfb5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Churchill was appointed Prime Minister of the United Kingdom on May 10, 1940, at the age of 65.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "tracer = LangChainTracer(project_name=\"Churchill v1\")\n",
    "llm.predict(\"How old was Churchill when he was appointed PM?\", callbacks=[tracer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a63e5-42a6-4671-bddd-925a0ba70e30",
   "metadata": {},
   "source": [
    "**Check updates in the Projects Area in LangSmith**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e77ae-23b8-4c45-aca6-dd3a4592a8d4",
   "metadata": {},
   "source": [
    "**Alternative way to do the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7057bd7f-ce18-41a1-a774-a65d253d444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"Cyrus v1\"):\n",
    "    llm.invoke(\"When did Cyrus The Great reign in Persia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a9b37-f05f-4823-8567-3e76d0ace2c7",
   "metadata": {},
   "source": [
    "## Creating Tags in LangSmith Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7ecac2-caa7-463c-b1e1-3ef70b7b9071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_7052\\3452238537.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n",
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_7052\\3452238537.py:14: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain(\"When did the first Cyrus king reign in Persia?\", tags=[\"Cyrus\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When did the first Cyrus king reign in Persia?',\n",
       " 'text': 'The first Cyrus king to reign in Persia was Cyrus the Great, who ruled from 559-530 BC.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, tags=[\"History\"])\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Say {input}\")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    tags=[\"Cyrus\", \"Persia\"])\n",
    "\n",
    "chain(\"When did the first Cyrus king reign in Persia?\", tags=[\"Cyrus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b82b7-36ae-4771-8cdd-8c8aaf3c1107",
   "metadata": {},
   "source": [
    "*See that this went to the default project since we did not set that differently*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4dc45-b3ec-4c30-9219-8129534c04c1",
   "metadata": {},
   "source": [
    "## Creating Groups in LangSmith Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c485bfe-8418-43c1-bbb8-c6425acbaeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Temp\\ipykernel_7052\\2347391940.py:24: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(question=\"Who did Julius Caesar marry?\", callbacks=group_manager)\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import (\n",
    "    trace_as_chain_group\n",
    ")\n",
    "\n",
    "with trace_as_chain_group(\"American History v1\") as group_manager:\n",
    "    pass\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "roman_llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"What is the answer to {question}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=roman_llm, \n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "with trace_as_chain_group(\"Roman History v1\") as group_manager:\n",
    "    chain.run(question=\"Who did Julius Caesar marry?\", callbacks=group_manager)\n",
    "    chain.run(question=\"Where did Julius Caesar fight?\", callbacks=group_manager)\n",
    "    chain.run(question=\"What was the name of the horse of Julius Caesar?\", callbacks=group_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd92c6-9a8f-49f2-9709-bedda1e5b4e6",
   "metadata": {},
   "source": [
    "## LangSmith Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11f46d9-d947-408d-82ae-8588503243df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Client.list_runs at 0x000001ADD3AC8040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "project_runs = client.list_runs(project_name=\"default\")\n",
    "project_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d671891-1330-4040-9d2c-6057f287c53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Client.list_runs at 0x000001ADD3AC8220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "todays_runs = client.list_runs(\n",
    "    project_name=\"default\",\n",
    "    start_time=datetime.now() - timedelta(days=1),\n",
    "    run_type=\"llm\"\n",
    ")\n",
    "todays_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf04f18-46ab-4332-b377-185329c43fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in todays_runs:\n",
    "    print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f1debf-da80-482e-abf9-6aaaca02bfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=UUID('41ba79f1-d22a-46d2-bdf0-d59b071d62a0') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 16, 10, 13, 59137) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 16, 10, 13, 836178) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T16:10:13.059137+00:00'}, {'name': 'end', 'time': '2025-06-29T16:10:13.836178+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Churchill was appointed Prime Minister of the United Kingdom on May 10, 1940, at the age of 65.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Churchill was appointed Prime Minister of the United Kingdom on May 10, 1940, at the age of 65.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 26, 'prompt_tokens': 17, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnotZydo3hk7eLtajGxRHkgFMMQGN', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--41ba79f1-d22a-46d2-bdf0-d59b071d62a0-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 26, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 26, 'prompt_tokens': 17, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnotZydo3hk7eLtajGxRHkgFMMQGN', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/41ba79f1-d22a-46d2-bdf0-d59b071d62a0?trace_id=41ba79f1-d22a-46d2-bdf0-d59b071d62a0&start_time=2025-06-29T16:10:13.059137' manifest_id=None status='success' prompt_tokens=17 completion_tokens=26 total_tokens=43 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.0000475') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.000039') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('41ba79f1-d22a-46d2-bdf0-d59b071d62a0') dotted_order='20250629T161013059137Z41ba79f1-d22a-46d2-bdf0-d59b071d62a0' in_dataset=False\n",
      "id=UUID('d5282018-3544-42f9-935d-1fa864e5bd29') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 16, 8, 9, 613671) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 16, 8, 10, 706176) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': 0, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T16:08:09.613671+00:00'}, {'name': 'end', 'time': '2025-06-29T16:08:10.706176+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 23, 'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoraHF3Rb8OjjmAbXQvpWUK1N4Hu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--d5282018-3544-42f9-935d-1fa864e5bd29-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 23, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 23, 'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoraHF3Rb8OjjmAbXQvpWUK1N4Hu', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=['ttt', 'History'] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/d5282018-3544-42f9-935d-1fa864e5bd29?trace_id=d5282018-3544-42f9-935d-1fa864e5bd29&start_time=2025-06-29T16:08:09.613671' manifest_id=None status='success' prompt_tokens=17 completion_tokens=23 total_tokens=40 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.000043') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.0000345') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('d5282018-3544-42f9-935d-1fa864e5bd29') dotted_order='20250629T160809613671Zd5282018-3544-42f9-935d-1fa864e5bd29' in_dataset=False\n",
      "id=UUID('b6587f4d-e489-47e0-aa6e-98ebeb212d53') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 16, 6, 30, 492528) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 16, 6, 31, 422540) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T16:06:30.492528+00:00'}, {'name': 'end', 'time': '2025-06-29T16:06:31.422540+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 66 years old when he was appointed Prime Minister of the United Kingdom on May 10, 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 66 years old when he was appointed Prime Minister of the United Kingdom on May 10, 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnopydQqkee50i70sY0CSeqotLzeg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--b6587f4d-e489-47e0-aa6e-98ebeb212d53-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnopydQqkee50i70sY0CSeqotLzeg', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/b6587f4d-e489-47e0-aa6e-98ebeb212d53?trace_id=b6587f4d-e489-47e0-aa6e-98ebeb212d53&start_time=2025-06-29T16:06:30.492528' manifest_id=None status='success' prompt_tokens=17 completion_tokens=27 total_tokens=44 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.000049') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.0000405') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('b6587f4d-e489-47e0-aa6e-98ebeb212d53') dotted_order='20250629T160630492528Zb6587f4d-e489-47e0-aa6e-98ebeb212d53' in_dataset=False\n",
      "id=UUID('a9777b79-4ad1-4a4a-8cdd-c3956800da4c') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 15, 29, 39, 316415) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 15, 29, 39, 836258) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T15:29:39.316415+00:00'}, {'name': 'end', 'time': '2025-06-29T15:29:39.836258+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 23, 'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoGJfuPVbRhU6lXguvhg5O9MX00y', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--a9777b79-4ad1-4a4a-8cdd-c3956800da4c-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 23, 'total_tokens': 40, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 23, 'prompt_tokens': 17, 'total_tokens': 40, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoGJfuPVbRhU6lXguvhg5O9MX00y', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/a9777b79-4ad1-4a4a-8cdd-c3956800da4c?trace_id=a9777b79-4ad1-4a4a-8cdd-c3956800da4c&start_time=2025-06-29T15:29:39.316415' manifest_id=None status='success' prompt_tokens=17 completion_tokens=23 total_tokens=40 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.000043') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.0000345') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('a9777b79-4ad1-4a4a-8cdd-c3956800da4c') dotted_order='20250629T152939316415Za9777b79-4ad1-4a4a-8cdd-c3956800da4c' in_dataset=False\n",
      "id=UUID('3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 15, 28, 20, 51005) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 15, 28, 20, 937178) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T15:28:20.051005+00:00'}, {'name': 'end', 'time': '2025-06-29T15:28:20.937178+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom on May 10, 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom on May 10, 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoF2oVYbYDWYeSGFVvuizslhzt4v', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 27, 'total_tokens': 44, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 27, 'prompt_tokens': 17, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoF2oVYbYDWYeSGFVvuizslhzt4v', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb?trace_id=3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb&start_time=2025-06-29T15:28:20.051005' manifest_id=None status='success' prompt_tokens=17 completion_tokens=27 total_tokens=44 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.000049') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.0000405') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb') dotted_order='20250629T152820051005Z3e67cd9a-2bbe-4030-b1e4-01faa8bc49fb' in_dataset=False\n",
      "id=UUID('1fc2fdbb-e394-4b77-8920-dfbb76595c4e') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 15, 23, 47, 628019) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 15, 23, 49, 75942) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T15:23:47.628019+00:00'}, {'name': 'end', 'time': '2025-06-29T15:23:49.075942+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in May 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 65 years old when he was appointed Prime Minister of the United Kingdom in May 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 24, 'prompt_tokens': 17, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoAec3RXOnk9rfwNsEZf4PWowXd6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--1fc2fdbb-e394-4b77-8920-dfbb76595c4e-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 24, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 24, 'prompt_tokens': 17, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnoAec3RXOnk9rfwNsEZf4PWowXd6', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/1fc2fdbb-e394-4b77-8920-dfbb76595c4e?trace_id=1fc2fdbb-e394-4b77-8920-dfbb76595c4e&start_time=2025-06-29T15:23:47.628019' manifest_id=None status='success' prompt_tokens=17 completion_tokens=24 total_tokens=41 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.0000445') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.000036') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('1fc2fdbb-e394-4b77-8920-dfbb76595c4e') dotted_order='20250629T152347628019Z1fc2fdbb-e394-4b77-8920-dfbb76595c4e' in_dataset=False\n",
      "id=UUID('eff14d82-ace8-44c2-9ec9-2771ad96aa48') name='ChatOpenAI' start_time=datetime.datetime(2025, 6, 29, 13, 24, 40, 734445) run_type='llm' end_time=datetime.datetime(2025, 6, 29, 13, 24, 41, 497299) extra={'invocation_params': {'model': 'gpt-3.5-turbo', 'model_name': 'gpt-3.5-turbo', 'stream': False, '_type': 'openai-chat', 'stop': None}, 'options': {'stop': None}, 'batch_size': 1, 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-3.5-turbo', 'ls_model_type': 'chat', 'ls_temperature': None, 'revision_id': '6d77281-dirty', 'ls_run_depth': 0}, 'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.3.45', 'library': 'langchain-core', 'platform': 'Windows-10-10.0.19045-SP0', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.25', 'langchain_core_version': '0.3.65', 'library_version': '0.3.65'}} error=None serialized=None events=[{'name': 'start', 'time': '2025-06-29T13:24:40.734445+00:00'}, {'name': 'end', 'time': '2025-06-29T13:24:41.497299+00:00'}] inputs={'messages': [[{'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'HumanMessage'], 'kwargs': {'content': 'How old was Churchill when he was appointed PM?', 'type': 'human'}}]]} outputs={'generations': [[{'text': 'Winston Churchill was 65 years old when he was appointed as the Prime Minister of the United Kingdom in 1940.', 'generation_info': {'finish_reason': 'stop', 'logprobs': None}, 'type': 'ChatGeneration', 'message': {'lc': 1, 'type': 'constructor', 'id': ['langchain', 'schema', 'messages', 'AIMessage'], 'kwargs': {'content': 'Winston Churchill was 65 years old when he was appointed as the Prime Minister of the United Kingdom in 1940.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 25, 'prompt_tokens': 17, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnmJKkny5098tX7VNFJTFVq9fk6I7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run--eff14d82-ace8-44c2-9ec9-2771ad96aa48-0', 'usage_metadata': {'input_tokens': 17, 'output_tokens': 25, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [], 'invalid_tool_calls': []}}}]], 'llm_output': {'token_usage': {'completion_tokens': 25, 'prompt_tokens': 17, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BnmJKkny5098tX7VNFJTFVq9fk6I7', 'service_tier': 'default'}, 'run': None, 'type': 'LLMResult'} reference_example_id=None parent_run_id=None tags=[] attachments={} session_id=UUID('d95e2125-6d3e-4561-af9a-4f4c5604e382') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/410572b9-b24c-4e4e-b0da-f2ca0e50da19/projects/p/d95e2125-6d3e-4561-af9a-4f4c5604e382/r/eff14d82-ace8-44c2-9ec9-2771ad96aa48?trace_id=eff14d82-ace8-44c2-9ec9-2771ad96aa48&start_time=2025-06-29T13:24:40.734445' manifest_id=None status='success' prompt_tokens=17 completion_tokens=25 total_tokens=42 prompt_token_details={'audio': 0, 'cache_read': 0} completion_token_details={'audio': 0, 'reasoning': 0} first_token_time=None total_cost=Decimal('0.000046') prompt_cost=Decimal('0.0000085') completion_cost=Decimal('0.0000375') prompt_cost_details=None completion_cost_details=None parent_run_ids=[] trace_id=UUID('eff14d82-ace8-44c2-9ec9-2771ad96aa48') dotted_order='20250629T132440734445Zeff14d82-ace8-44c2-9ec9-2771ad96aa48' in_dataset=False\n"
     ]
    }
   ],
   "source": [
    "todays_runs = client.list_runs(\n",
    "     project_name=\"Churchill v1\",\n",
    "     start_time=datetime.now() - timedelta(days=1),\n",
    "     run_type=\"llm\",\n",
    " )\n",
    "\n",
    "for run in todays_runs:\n",
    "     print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5ff50-9fd8-42aa-b9a3-cce04c9449b8",
   "metadata": {},
   "source": [
    "## Adding metadata to filter runs\n",
    "One possible use of this: making A/B tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05f0807d-ddea-4ae7-a463-d6e415af7448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the companion of Don Quixote?', 'text': 'Sancho Panza'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = ChatOpenAI()\n",
    "chain = LLMChain.from_string(\n",
    "    llm=chat_model, \n",
    "    template=\"What's the answer to {input}?\")\n",
    "\n",
    "chain(\n",
    "    {\"input\": \"Who was the companion of Don Quixote?\"}, \n",
    "    metadata={\"source\": \"Cervantes\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c600284e-c2a5-4a0c-85a1-a31ffbbcb477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "runs = list(client.list_runs(\n",
    "    project_name=\"default\",\n",
    "    filter='has(metadata, \\'{\"source\": \"Cervantes\"}\\')',\n",
    "))\n",
    "\n",
    "print(list(runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e63f8-8c49-43b5-88f9-42c21e6a645f",
   "metadata": {},
   "source": [
    "## Evaluating your LLM App with a Test Dataset in LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37619317-242f-4a52-b05e-71ceaa8ac5d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langsmith\\utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langsmith\\client.py:828\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    823\u001b[39m         method,\n\u001b[32m    824\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    825\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    826\u001b[39m         **request_kwargs,\n\u001b[32m    827\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langsmith\\utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33mElementary Animal Questions v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Storing inputs in a dataset lets us\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# run chains and LLMs over a shared set of examples.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQuestions and answers about animal phylogenetics.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_prompt, output_answer \u001b[38;5;129;01min\u001b[39;00m example_inputs:\n\u001b[32m     22\u001b[39m     client.create_example(\n\u001b[32m     23\u001b[39m         inputs={\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: input_prompt},\n\u001b[32m     24\u001b[39m         outputs={\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m: output_answer},\n\u001b[32m     25\u001b[39m         dataset_id=dataset.id,\n\u001b[32m     26\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langsmith\\client.py:3417\u001b[39m, in \u001b[36mClient.create_dataset\u001b[39m\u001b[34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[39m\n\u001b[32m   3414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3415\u001b[39m     dataset[\u001b[33m\"\u001b[39m\u001b[33moutputs_schema_definition\u001b[39m\u001b[33m\"\u001b[39m] = outputs_schema\n\u001b[32m-> \u001b[39m\u001b[32m3417\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3418\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3419\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3420\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_orjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3422\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3423\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3425\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas.Dataset(\n\u001b[32m   3426\u001b[39m     **response.json(),\n\u001b[32m   3427\u001b[39m     _host_url=\u001b[38;5;28mself\u001b[39m._host_url,\n\u001b[32m   3428\u001b[39m     _tenant_id=\u001b[38;5;28mself\u001b[39m._get_optional_tenant_id(),\n\u001b[32m   3429\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langsmith\\client.py:873\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    868\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    869\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    870\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    871\u001b[39m     )\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    874\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    875\u001b[39m     )\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    877\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    878\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    879\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     )\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "example_inputs = [\n",
    "  (\"What is the largest mammal?\", \"The blue whale\"),\n",
    "  (\"What do mammals and birds have in common?\", \"They are both warm-blooded\"),\n",
    "  (\"What are reptiles known for?\", \"Having scales\"),\n",
    "  (\"What's the main characteristic of amphibians?\", \"They live both in water and on land\"),\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Elementary Animal Questions v1\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, \n",
    "    description=\"Questions and answers about animal phylogenetics.\",\n",
    ")\n",
    "\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cca294-91b2-44a8-9ac0-99e681ca7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"qa\",\n",
    "        \"context_qa\",\n",
    "        \"cot_qa\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577490a-fbab-4c08-98dd-7690df4a6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "llm = ChatOpenAI()\n",
    "run_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=llm,\n",
    "    client=client,\n",
    "    evaluation=evaluation_config,\n",
    "    project_name=\"evalproject v1\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
