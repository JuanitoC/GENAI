"""
üß† Resumen de lo que hace este script:
Usa LangChain + OpenAI GPT para interactuar con un chatbot.

Permite manejar memoria por sesi√≥n, como si tuvieras m√∫ltiples usuarios o sesiones independientes.

Muestra la diferencia entre:

Un chatbot sin memoria (inicial).

Un chatbot con memoria persistente por sesi√≥n.

Un chatbot con memoria limitada a los √∫ltimos mensajes (simulando olvido).
"""

# Ignora las advertencias de deprecaci√≥n espec√≠ficas de LangChain
import warnings
from langchain._api import LangChainDeprecationWarning
warnings.simplefilter("ignore", category=LangChainDeprecationWarning)

# Carga las variables de entorno desde un archivo .env
import os
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())  # Carga el archivo .env autom√°ticamente
openai_api_key = os.environ["OPENAI_API_KEY"]  # Obtiene la clave de API

# Crea un chatbot con el modelo GPT-3.5-Turbo usando LangChain
from langchain_openai import ChatOpenAI
chatbot = ChatOpenAI(model="gpt-3.5-turbo")

# Importa clase para representar mensajes del usuario
from langchain_core.messages import HumanMessage

# Primer mensaje al chatbot
messagesToTheChatbot = [
    HumanMessage(content="My favorite color is blue."),
]

# Env√≠a el mensaje y recibe respuesta
response = chatbot.invoke(messagesToTheChatbot)

# Muestra mensaje original y respuesta del chatbot
print("\n----------\n")
print("My favorite color is blue.")
print("\n----------\n")
print(response.content)
print("\n----------\n")

# Segunda interacci√≥n: pregunta por el color favorito
response = chatbot.invoke([
    HumanMessage(content="What is my favorite color?")
])
print("\n----------\n")
print("What is my favorite color?")
print("\n----------\n")
print(response.content)
print("\n----------\n")

# ---- Secci√≥n: Chat con historial de mensajes gestionado manualmente ----

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# Diccionario en memoria para guardar sesiones de chat
chatbotMemory = {}

# Funci√≥n para obtener o crear historial para una sesi√≥n espec√≠fica
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in chatbotMemory:
        chatbotMemory[session_id] = ChatMessageHistory()
    return chatbotMemory[session_id]

# Crea un chatbot con historial de mensajes por sesi√≥n
chatbot_with_message_history = RunnableWithMessageHistory(
    chatbot, 
    get_session_history
)

# Define la primera sesi√≥n con ID "001"
session1 = {"configurable": {"session_id": "001"}}

# Env√≠a un mensaje en la sesi√≥n 1
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="My favorite color is red.")],
    config=session1,
)
print("\n----------\n")
print("My favorite color is red.")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Pregunta por el color favorito dentro de la misma sesi√≥n (deber√≠a recordar "red")
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="What's my favorite color?")],
    config=session1,
)
print("\n----------\n")
print("What's my favorite color? (in session1)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Segunda sesi√≥n con ID diferente
session2 = {"configurable": {"session_id": "002"}}

# Pregunta por el color favorito en una sesi√≥n nueva (no deber√≠a recordar nada)
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="What's my favorite color?")],
    config=session2,
)
print("\n----------\n")
print("What's my favorite color? (in session2)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Regresa a sesi√≥n1 y vuelve a preguntar
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="What's my favorite color?")],
    config=session1,
)
print("\n----------\n")
print("What's my favorite color? (in session1 again)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# A√±ade informaci√≥n a la sesi√≥n2
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="Mi name is Julio.")],
    config=session2,
)
print("\n----------\n")
print("Mi name is Julio. (in session2)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Pregunta por el nombre en sesi√≥n2 (deber√≠a recordar "Julio")
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="What is my name?")],
    config=session2,
)
print("\n----------\n")
print("What is my name? (in session2)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Confusi√≥n: se vuelve a usar sesi√≥n1 pero el comentario dice "session2"
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="What is my favorite color?")],
    config=session1,
)
print("\n----------\n")
print("What is my favorite color? (in session2)")  # ¬°Este comentario parece incorrecto!
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# ---- Secci√≥n: Chat con memoria limitada (solo √∫ltimos mensajes) ----

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough

# Funci√≥n para limitar la memoria a los √∫ltimos N mensajes
def limited_memory_of_messages(messages, number_of_messages_to_keep=2):
    return messages[-number_of_messages_to_keep:]

# Plantilla con un sistema y mensajes del usuario
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

# Cadena que limita los mensajes y aplica el prompt antes de invocar el chatbot
limitedMemoryChain = (
    RunnablePassthrough.assign(messages=lambda x: limited_memory_of_messages(x["messages"]))
    | prompt 
    | chatbot
)

# Crea una versi√≥n del chatbot con memoria limitada y sesiones
chatbot_with_limited_message_history = RunnableWithMessageHistory(
    limitedMemoryChain,
    get_session_history,
    input_messages_key="messages",
)

# Se sigue usando la sesi√≥n1, agregando nuevos mensajes
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="My favorite vehicles are Vespa scooters.")],
    config=session1,
)
print("\n----------\n")
print("My favorite vehicles are Vespa scooters. (in session1)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="My favorite city is San Francisco.")],
    config=session1,
)
print("\n----------\n")
print("My favorite city is San Francisco. (in session1)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Pregunta al chatbot con memoria limitada (√∫ltimos 2 mensajes) ‚Äî puede que ya no recuerde el color
responseFromChatbot = chatbot_with_limited_message_history.invoke(
    {
        "messages": [HumanMessage(content="what is my favorite color?")],
    },
    config=session1,
)
print("\n----------\n")
print("what is my favorite color? (chatbot with memory limited to the last 3 messages)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")

# Pregunta al chatbot con memoria completa ‚Äî deber√≠a recordar
responseFromChatbot = chatbot_with_message_history.invoke(
    [HumanMessage(content="what is my favorite color?")],
    config=session1,
)
print("\n----------\n")
print("what is my favorite color? (chatbot with unlimited memory)")
print("\n----------\n")
print(responseFromChatbot.content)
print("\n----------\n")
