{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Aplicación de Extracción de Datos Clave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "* Crearemos una aplicación para **extraer información estructurada de texto no estructurado**. Imagina, por ejemplo, que quieres extraer el nombre, apellido y país de los usuarios que envían comentarios en la web de tu empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d02e49-5d84-4947-8419-4fec37b0c05f",
   "metadata": {},
   "source": [
    "## Conéctate con el archivo .env ubicado en el mismo directorio de este notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Conéctate con un LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTA: Dado que actualmente es el mejor LLM del mercado, usaremos OpenAI por defecto. Verás cómo conectarte con otros LLMs de código abierto como Llama3 o Mistral en una próxima lección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba89426-c952-43a3-aa6c-1a7430d7aa8c1",
   "metadata": {},
   "source": [
    "## Define qué información quieres extraer\n",
    "* **Usaremos Pydantic para definir un esquema para extraer información personal**.\n",
    "* Pydantic es una librería de Python utilizada para la validación de datos. Ayuda a asegurar que los datos que recibe tu programa coincidan con el formato que esperas, y proporciona mensajes de error útiles cuando los datos no cumplen con tus especificaciones. Esencialmente, Pydantic te permite hacer que las estructuras de datos en Python se ajusten a tipos y restricciones específicas, haciendo tu código más robusto y resistente a errores.\n",
    "* **Documenta los atributos y el propio esquema**: Esta información se envía al LLM y se utiliza para mejorar la calidad de la extracción de información.\n",
    "* ¡No fuerces al LLM a inventar información! **Importamos Optional para los atributos, permitiendo que el LLM devuelva None si no sabe la respuesta**.\n",
    "* Cuando usas Optional en las anotaciones de tipo, indicas que una variable puede ser del tipo especificado o puede ser None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa25289-7fa7-468b-a981-495da9bb4a5d",
   "metadata": {},
   "source": [
    "#### Definamos los datos que queremos extraer de una persona.\n",
    "* Observa abajo que es una buena práctica escribir un doc-string explicativo (comentarios) para ayudar al modelo de chat a entender qué datos queremos extraer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71b3d81a-e4d3-4956-807b-1ab147146390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3672: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Información sobre una persona.\"\"\"\n",
    "\n",
    "    # ^ Doc-string para la entidad Person.\n",
    "    # Este doc-string se envía al LLM como la descripción del esquema Person,\n",
    "    # y puede ayudar a mejorar los resultados de la extracción.\n",
    "\n",
    "    # Nota:\n",
    "    # 1. Cada campo es `optional` -- esto permite que el modelo decline extraerlo.\n",
    "    # 2. Cada campo tiene una `description` -- esta descripción es usada por el LLM.\n",
    "    # Tener una buena descripción puede ayudar a mejorar los resultados de la extracción.\n",
    "    name: Optional[str] = Field(\n",
    "        default=None, description=\"El nombre de la persona\"\n",
    "    )\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"El apellido de la persona si se conoce\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"El país de la persona si se conoce\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219dde9c-3139-442c-a3be-1b9185f7a644",
   "metadata": {},
   "source": [
    "## Define el extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301c8fb-c905-4cd2-aa04-68eb7399ecf3",
   "metadata": {},
   "source": [
    "Nuestro extractor será una cadena con la plantilla de prompt y un modelo de chat con las instrucciones de extracción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab077d5b-d86c-4d0e-baac-b19cbe6ace83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Define un prompt personalizado para dar instrucciones y contexto adicional.\n",
    "# 1) Puedes agregar ejemplos en la plantilla del prompt para mejorar la calidad de la extracción\n",
    "# 2) Puedes introducir parámetros adicionales para tener en cuenta el contexto (por ejemplo, incluir metadatos\n",
    "#    sobre el documento del que se extrajo el texto.)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un algoritmo experto en extracción. \"\n",
    "            \"Solo extrae información relevante del texto. \"\n",
    "            \"Si no sabes el valor de un atributo solicitado para extraer, \"\n",
    "            \"devuelve null para el valor del atributo.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c14b0-976b-4340-bcb3-46109584d987",
   "metadata": {},
   "source": [
    "* Necesitamos usar un modelo que soporte llamadas a funciones/herramientas.\n",
    "* Por favor revisa [la documentación](https://python.langchain.com/v0.2/docs/concepts/#function-tool-calling) para ver una lista de algunos modelos que pueden usarse con esta API.\n",
    "* **Usaremos .with_structured_output() para añadir las instrucciones de extracción a nuestro modelo de chat**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb3cd0d-fc9a-4223-a1ef-5857dc0e4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:1677: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:1690: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05698c54-da74-4ff5-b7ff-d9bb22d6f726",
   "metadata": {},
   "source": [
    "## Prueba la aplicación de extracción\n",
    "Mira cómo la aplicación extrae el nombre, apellido y país de una reseña de usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082c7c53-0a94-4a59-b5a7-d3a186402467",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I absolutely love this product! It's been a game-changer for my daily routine. The quality is top-notch and the customer service is outstanding. I've recommended it to all my friends and family. - Sarah Johnson, USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39cb512c-5b2e-4aeb-9821-6395809a8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Sarah', lastname='Johnson', country='USA')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05023e96-9c9b-4102-b902-7e244b78ee6f",
   "metadata": {},
   "source": [
    "* **Ten en cuenta que esta capacidad de extracción es generativa**, lo que significa que nuestro modelo puede realizar una variedad de tareas más allá de lo esperado. Por ejemplo, el modelo podría inferir el género de un usuario a partir de su nombre, incluso cuando esta información no se proporciona explícitamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14033470-3abb-4cc5-ad4c-da9370e0a6d6",
   "metadata": {},
   "source": [
    "## Extracción de una lista de entidades en lugar de una sola entidad\n",
    "* En proyectos reales probablemente trabajarás con un texto grande que incluya más de una reseña de usuario. **Podemos extraer los datos clave de varios usuarios anidando modelos de Pydantic**.\n",
    "* Observa cómo la definición del modelo Data incluye el modelo Person. Esto se llama técnicamente “anidar” modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40267cdd-9e8c-4ca8-b90f-4197b99f3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Información sobre una persona.\"\"\"\n",
    "\n",
    "    # ^ Doc-string para la entidad Person.\n",
    "    # Este doc-string se envía al LLM como la descripción del esquema Person,\n",
    "    # y puede ayudar a mejorar los resultados de la extracción.\n",
    "\n",
    "    # Nota:\n",
    "    # 1. Cada campo es `optional` -- esto permite que el modelo decline extraerlo.\n",
    "    # 2. Cada campo tiene una `description` -- esta descripción es usada por el LLM.\n",
    "    # Tener una buena descripción puede ayudar a mejorar los resultados de la extracción.\n",
    "    name: Optional[str] = Field(\n",
    "        default=None, description=\"El nombre de la persona\"\n",
    "    )\n",
    "    lastname: Optional[str] = Field(\n",
    "        default=None, description=\"El apellido de la persona si se conoce\"\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        default=None, description=\"El país de la persona si se conoce\"\n",
    "    )\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Datos extraídos sobre personas.\"\"\"\n",
    "\n",
    "    # Crea un modelo para poder extraer múltiples entidades.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7155b07-79e9-4495-b832-447ed255b88c",
   "metadata": {},
   "source": [
    "Observa cómo ahora estamos usando el modelo Data con el llm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4572231-c88c-474f-8421-788ed4f1115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:1677: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\Juan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_openai\\chat_models\\base.py:1690: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39646a67-a02c-4e80-a2ad-3ea2cf6b8c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"I'm so impressed with this product! It has truly transformed how I approach my daily tasks. The quality exceeds my expectations, and the customer support is truly exceptional. I've already suggested it to all my colleagues and relatives. - Emily Clarke, Canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ffbad47-807a-4607-b4e1-e6b472b2c9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Emily', lastname='Clarke', country='Canada')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": comment})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696aba01-c18a-4190-99fa-a8eaed089729",
   "metadata": {},
   "source": [
    "#### Veamos esto en acción con un texto que contiene varias reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e128d1fe-54d1-4c9f-893c-a93b831a8df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Alice', lastname='Johnson', country='Canadá'), Person(name='Bob', lastname='Smith', country='EE.UU.')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de texto de entrada que menciona a varias personas\n",
    "text_input = \"\"\"\n",
    "Alice Johnson de Canadá revisó recientemente un libro que le encantó. Mientras tanto, Bob Smith de EE.UU. compartió sus ideas sobre el mismo libro en una reseña diferente. Ambas reseñas fueron muy perspicaces.\n",
    "\"\"\"\n",
    "\n",
    "# Invoca la cadena de procesamiento sobre el texto\n",
    "response = chain.invoke({\"text\": text_input})\n",
    "\n",
    "# Muestra los datos extraídos\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
